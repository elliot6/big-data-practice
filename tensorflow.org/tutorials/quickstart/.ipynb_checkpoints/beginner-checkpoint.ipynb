{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/quickstart/beginner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.14005604, -0.7228776 , -0.33083138, -0.0903234 ,  0.31242892,\n",
       "         0.3944592 , -0.47280464,  0.24070911, -0.04783392, -0.83265513]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12235604, 0.05162477, 0.07640497, 0.09717911, 0.14537376,\n",
       "        0.15780157, 0.06629235, 0.13531269, 0.10139717, 0.04625752]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.846417"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2959 - accuracy: 0.9126\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1416 - accuracy: 0.9577\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1062 - accuracy: 0.9683\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.0866 - accuracy: 0.9729\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.0749 - accuracy: 0.9764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x659d38e10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 0s - loss: 0.0381 - accuracy: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0751671346894931, 0.9775]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=30015, shape=(5, 10), dtype=float32, numpy=\n",
       "array([[6.48280896e-09, 7.92550026e-09, 3.14090744e-06, 8.20994101e-05,\n",
       "        2.54264276e-10, 3.12852336e-07, 1.38636173e-13, 9.99903440e-01,\n",
       "        1.50709496e-07, 1.08351751e-05],\n",
       "       [6.80250309e-07, 1.48300751e-04, 9.99657393e-01, 1.81769821e-04,\n",
       "        4.79860724e-15, 9.29031012e-06, 1.68258600e-06, 4.56772647e-14,\n",
       "        7.83596704e-07, 3.86014513e-15],\n",
       "       [1.66240550e-08, 9.99415994e-01, 7.42868579e-05, 1.95611101e-05,\n",
       "        2.29228172e-05, 4.15415161e-05, 1.79263334e-05, 2.79603759e-04,\n",
       "        1.27544961e-04, 4.82949076e-07],\n",
       "       [9.99588430e-01, 1.47611825e-08, 3.30711155e-05, 2.60882916e-06,\n",
       "        6.18691411e-06, 3.91915955e-06, 3.91831873e-06, 3.58475372e-04,\n",
       "        1.89862970e-08, 3.39326084e-06],\n",
       "       [2.35881107e-05, 3.65265906e-09, 2.45750507e-05, 7.43642431e-07,\n",
       "        9.92280662e-01, 2.52838549e-06, 3.04374371e-05, 2.61323177e-04,\n",
       "        9.46830710e-07, 7.37514952e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
